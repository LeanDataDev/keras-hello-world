{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydot\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_features = abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\", header=None, \n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "\n",
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.435, 0.335, 0.11 , ..., 0.136, 0.077, 0.097],\n",
       "       [0.585, 0.45 , 0.125, ..., 0.354, 0.207, 0.225],\n",
       "       [0.655, 0.51 , 0.16 , ..., 0.396, 0.282, 0.37 ],\n",
       "       ...,\n",
       "       [0.53 , 0.42 , 0.13 , ..., 0.374, 0.167, 0.249],\n",
       "       [0.395, 0.315, 0.105, ..., 0.118, 0.091, 0.119],\n",
       "       [0.45 , 0.355, 0.12 , ..., 0.115, 0.067, 0.16 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_features = np.array(abalone_features)\n",
    "abalone_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_model = tf.keras.Sequential([\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 72.9131\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 14.4226\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 8.5919\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 8.1087\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 7.6644\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 7.3025\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 7.0089\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 6.8032\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 6.6521\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 6.5462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fce5c719ca0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = preprocessing.Normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize.adapt(abalone_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 95.1110\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 57.9207\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 18.7403\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 6.0913\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 5.0731\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 4.9955\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 4.9960\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 4.9822\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 4.9607\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 4.9518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcf01108a60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_abalone_model = tf.keras.Sequential([\n",
    "  normalize,\n",
    "  layers.Dense(64),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "norm_abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                           optimizer = tf.optimizers.Adam())\n",
    "\n",
    "norm_abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv(\"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'AddV2_1:0' shape=(None,) dtype=float32>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a symbolic input\n",
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "\n",
    "# Do a calculation using is\n",
    "result = 2*input + 1\n",
    "\n",
    "# the result doesn't have a value\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = tf.keras.Model(inputs=input, outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(calc(1).numpy())\n",
    "print(calc(2).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': <tf.Tensor 'sex_1:0' shape=(None, 1) dtype=string>,\n",
       " 'age': <tf.Tensor 'age_1:0' shape=(None, 1) dtype=float32>,\n",
       " 'n_siblings_spouses': <tf.Tensor 'n_siblings_spouses_1:0' shape=(None, 1) dtype=float32>,\n",
       " 'parch': <tf.Tensor 'parch_1:0' shape=(None, 1) dtype=float32>,\n",
       " 'fare': <tf.Tensor 'fare_1:0' shape=(None, 1) dtype=float32>,\n",
       " 'class': <tf.Tensor 'class_1:0' shape=(None, 1) dtype=string>,\n",
       " 'deck': <tf.Tensor 'deck_1:0' shape=(None, 1) dtype=string>,\n",
       " 'embark_town': <tf.Tensor 'embark_town_1:0' shape=(None, 1) dtype=string>,\n",
       " 'alone': <tf.Tensor 'alone_1:0' shape=(None, 1) dtype=string>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'normalization_3/truediv:0' shape=(None, 4) dtype=float32>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = preprocessing.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "\n",
    "  lookup = preprocessing.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "  one_hot = preprocessing.CategoryEncoding(max_tokens=lookup.vocab_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "\n",
    "tf.keras.utils.plot_model(model = titanic_preprocessing , rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features_dict = {name: np.array(value) \n",
    "                         for name, value in titanic_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 33), dtype=float32, numpy=\n",
       "array([[-0.61 ,  0.395, -0.479, -0.497,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "titanic_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(preprocessing_head, inputs):\n",
    "  body = tf.keras.Sequential([\n",
    "    layers.Dense(64),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  preprocessed_inputs = preprocessing_head(inputs)\n",
    "  result = body(preprocessed_inputs)\n",
    "  model = tf.keras.Model(inputs, result)\n",
    "\n",
    "  model.compile(loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "                optimizer=tf.optimizers.Adam())\n",
    "  return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5538\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4924\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4614\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4437\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4331\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4271\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4242\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4219\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4219\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcf0077cdc0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/szzz/.cache/pypoetry/virtualenvs/keras-hello-world-UD-2I3E_-py3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/szzz/.cache/pypoetry/virtualenvs/keras-hello-world-UD-2I3E_-py3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: test/assets\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcf004c7af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "titanic_model.save('test')\n",
    "reloaded = tf.keras.models.load_model('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-1.942]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[-1.942]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "\n",
    "before = titanic_model(features_dict)\n",
    "after = reloaded(features_dict)\n",
    "assert (before-after)<1e-3\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def slices(features):\n",
    "  for i in itertools.count():\n",
    "    # For each feature take index `i`\n",
    "    example = {name:values[i] for name, values in features.items()}\n",
    "    yield example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : male\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : Third\n",
      "deck               : unknown\n",
      "embark_town        : Southampton\n",
      "alone              : n\n"
     ]
    }
   ],
   "source": [
    "for example in slices(titanic_features_dict):\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ds = tf.data.Dataset.from_tensor_slices(titanic_features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : b'male'\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : b'Third'\n",
      "deck               : b'unknown'\n",
      "embark_town        : b'Southampton'\n",
      "alone              : b'n'\n"
     ]
    }
   ],
   "source": [
    "for example in features_ds:\n",
    "  for name, value in example.items():\n",
    "    print(f\"{name:19s}: {value}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_ds = tf.data.Dataset.from_tensor_slices((titanic_features_dict, titanic_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_batches = titanic_ds.shuffle(len(titanic_labels)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4205\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4200\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4191\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4202\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcf001e81f0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(titanic_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
      "32768/30874 [===============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "titanic_file_path = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_csv_ds = tf.data.experimental.make_csv_dataset(\n",
    "    titanic_file_path,\n",
    "    batch_size=5, # Artificially small to make examples easier to show.\n",
    "    label_name='survived',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'male' b'male' b'male' b'female' b'male']\n",
      "age                 : [28. 21. 28. 28. 36.]\n",
      "n_siblings_spouses  : [0 0 0 1 0]\n",
      "parch               : [0 0 0 0 0]\n",
      "fare                : [26.55   7.775 29.7   89.104  7.496]\n",
      "class               : [b'First' b'Third' b'First' b'First' b'Third']\n",
      "deck                : [b'C' b'unknown' b'C' b'C' b'unknown']\n",
      "embark_town         : [b'Southampton' b'Southampton' b'Cherbourg' b'Cherbourg' b'Southampton']\n",
      "alone               : [b'y' b'y' b'y' b'n' b'y']\n",
      "\n",
      "label               : [0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "for batch, label in titanic_csv_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\n",
      "409600/405373 [==============================] - 1s 2us/step\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz = tf.keras.utils.get_file(\n",
    "    'Metro_Interstate_Traffic_Volume.csv.gz', \n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\",\n",
    "    cache_dir='.', cache_subdir='traffic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday             : [b'None' b'None' b'None' b'None' b'None']\n",
      "temp                : [297.84 273.22 281.27 271.53 267.76]\n",
      "rain_1h             : [0. 0. 0. 0. 0.]\n",
      "snow_1h             : [0. 0. 0. 0. 0.]\n",
      "clouds_all          : [36 90 64 40 90]\n",
      "weather_main        : [b'Clouds' b'Clouds' b'Fog' b'Clouds' b'Haze']\n",
      "weather_description : [b'scattered clouds' b'overcast clouds' b'fog' b'scattered clouds' b'haze']\n",
      "date_time           : [b'2013-08-25 10:00:00' b'2013-03-25 18:00:00' b'2013-11-16 22:00:00'\n",
      " b'2012-10-29 06:00:00' b'2012-11-24 01:00:00']\n",
      "\n",
      "label               : [4028 4000 2671 5503  611]\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz_ds = tf.data.experimental.make_csv_dataset(\n",
    "    traffic_volume_csv_gz,\n",
    "    batch_size=256,\n",
    "    label_name='traffic_volume',\n",
    "    num_epochs=1,\n",
    "    compression_type=\"GZIP\")\n",
    "\n",
    "for batch, label in traffic_volume_csv_gz_ds.take(1):\n",
    "  for key, value in batch.items():\n",
    "    print(f\"{key:20s}: {value[:5]}\")\n",
    "  print()\n",
    "  print(f\"{'label':20s}: {label[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "CPU times: user 15.5 s, sys: 7.35 s, total: 22.9 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, (batch, label) in enumerate(traffic_volume_csv_gz_ds.repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "CPU times: user 1.47 s, sys: 387 ms, total: 1.86 s\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "caching = traffic_volume_csv_gz_ds.cache().shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(caching.shuffle(1000).repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "CPU times: user 2.3 s, sys: 1.12 s, total: 3.43 s\n",
      "Wall time: 2.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "snapshot = tf.data.experimental.snapshot('titanic.tfsnap')\n",
    "snapshotting = traffic_volume_csv_gz_ds.apply(snapshot).shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(snapshotting.shuffle(1000).repeat(20)):\n",
    "  if i % 40 == 0:\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\n",
      "160317440/160313983 [==============================] - 35s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fonts_zip = tf.keras.utils.get_file(\n",
    "    'fonts.zip',  \"https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\",\n",
    "    cache_dir='.', cache_subdir='fonts',\n",
    "    extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fonts/AGENCY.csv',\n",
       " 'fonts/ARIAL.csv',\n",
       " 'fonts/BAITI.csv',\n",
       " 'fonts/BANKGOTHIC.csv',\n",
       " 'fonts/BASKERVILLE.csv',\n",
       " 'fonts/BAUHAUS.csv',\n",
       " 'fonts/BELL.csv',\n",
       " 'fonts/BERLIN.csv',\n",
       " 'fonts/BERNARD.csv',\n",
       " 'fonts/BITSTREAMVERA.csv']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "font_csvs =  sorted(str(p) for p in pathlib.Path('fonts').glob(\"*.csv\"))\n",
    "\n",
    "font_csvs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(font_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=10, num_epochs=1,\n",
    "    num_parallel_reads=20,\n",
    "    shuffle_buffer_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=10, num_epochs=1,\n",
    "    num_parallel_reads=20,\n",
    "    shuffle_buffer_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "font                : [b'OCRA' b'OCRA' b'OCRA' b'ROMAN' b'BUXTON' b'GIGI' b'CANDARA' b'NIAGARA'\n",
      " b'SCRIPTB' b'CANDARA']\n",
      "fontVariant         : [b'scanned' b'scanned' b'scanned' b'ROMANT' b'BUXTON SKETCH' b'GIGI'\n",
      " b'CANDARA' b'NIAGARA SOLID' b'SCRIPT MT BOLD' b'CANDARA']\n",
      "m_label             : [   60    56    88  1076  8730   180  8486  8220 61442  8734]\n",
      "strength            : [0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]\n",
      "italic              : [0 0 0 1 0 0 0 0 1 0]\n",
      "orientation         : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "m_top               : [ 0  0  0 56 26 42 41 32 37 56]\n",
      "m_left              : [ 0  0  0 21 22 27 21 21 15 22]\n",
      "originalH           : [10 14 14 45 52 12 43 14 64 24]\n",
      "originalW           : [ 8  8  8 60 32 13 43 13 63 46]\n",
      "h                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "w                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "r0c0                : [  1   1 255   1   1   1   1   1   1   1]\n",
      "r0c1                : [  1   1 255   1   1   1   1   1   1   1]\n",
      "r0c2                : [  1   1 255   1   1   1   1   1   1  17]\n",
      "r0c3                : [  1   1 255   1   1   1   1   1   1 154]\n",
      "...\n",
      "[total: 412 features]\n"
     ]
    }
   ],
   "source": [
    "for features in fonts_ds.take(1):\n",
    "  for i, (name, value) in enumerate(features.items()):\n",
    "    if i>15:\n",
    "      break\n",
    "    print(f\"{name:20s}: {value}\")\n",
    "print('...')\n",
    "print(f\"[total: {len(features)} features]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def make_images(features):\n",
    "  image = [None]*400\n",
    "  new_feats = {}\n",
    "\n",
    "  for name, value in features.items():\n",
    "    match = re.match('r(\\d+)c(\\d+)', name)\n",
    "    if match:\n",
    "      image[int(match.group(1))*20+int(match.group(2))] = value\n",
    "    else:\n",
    "      new_feats[name] = value\n",
    "\n",
    "  image = tf.stack(image, axis=0)\n",
    "  image = tf.reshape(image, [20, 20, -1])\n",
    "  new_feats['image'] = image\n",
    "\n",
    "  return new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_image_ds = fonts_ds.map(make_images)\n",
    "\n",
    "for features in fonts_image_ds.take(1):\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szzz/.cache/pypoetry/virtualenvs/keras-hello-world-UD-2I3E_-py3.8/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 43845 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/home/szzz/.cache/pypoetry/virtualenvs/keras-hello-world-UD-2I3E_-py3.8/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 43845 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,6), dpi=120)\n",
    "\n",
    "for n in range(9):\n",
    "  plt.subplot(3,3,n+1)\n",
    "  plt.imshow(features['image'][..., n])\n",
    "  plt.title(chr(features['m_label'][n]))\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pathlib.Path(titanic_file_path).read_text()\n",
    "lines = text.split('\\n')[1:-1]\n",
    "\n",
    "all_strings = [str()]*10\n",
    "all_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=all_strings) \n",
    "\n",
    "for f in features:\n",
    "  print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, '', 0.0, 0, 0, 0.0, '', '', '', '']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_types = [int(), str(), float(), int(), int(), float(), str(), str(), str(), str()]\n",
    "titanic_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: int32, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: float32, shape: (627,)\n",
      "type: int32, shape: (627,)\n",
      "type: int32, shape: (627,)\n",
      "type: float32, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults=titanic_types) \n",
    "\n",
    "for f in features:\n",
    "  print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "simple_titanic = tf.data.experimental.CsvDataset(titanic_file_path, record_defaults=titanic_types, header=True)\n",
    "\n",
    "for example in simple_titanic.take(1):\n",
    "  print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "def decode_titanic_line(line):\n",
    "  return tf.io.decode_csv(line, titanic_types)\n",
    "\n",
    "manual_titanic = (\n",
    "    # Load the lines of text\n",
    "    tf.data.TextLineDataset(titanic_file_path)\n",
    "    # Skip the header row.\n",
    "    .skip(1)\n",
    "    # Decode the line.\n",
    "    .map(decode_titanic_line)\n",
    ")\n",
    "\n",
    "for example in manual_titanic.take(1):\n",
    "  print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENCY,AGENCY FB,64258,0.400000,0,0.000000,35,21,51,22,20,20,1,1,1,21,101,210,255,255,255,255,255,255,255,255,255,255,255,255,255,255,1,1,1,93,255,255,255,176,146,146,146,146,146,146,146,146,216,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,141,141,141,182,255,255,255,172,141,141,141,115,1,1,1,1,163,255,255,255,255,255,255,255,255,255,255,255,255,255,255,209,1,1,1,1,163,255,255,255,6,6,6,96,255,255,255,74,6,6,6,5,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255\n"
     ]
    }
   ],
   "source": [
    "font_line = pathlib.Path(font_csvs[0]).read_text().splitlines()[1]\n",
    "print(font_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_font_features = font_line.count(',')+1\n",
    "font_column_types = [str(), str()] + [float()]*(num_font_features-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fonts/AGENCY.csv'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "font_csvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_font_ds = tf.data.experimental.CsvDataset(\n",
    "    font_csvs, \n",
    "    record_defaults=font_column_types, \n",
    "    header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n"
     ]
    }
   ],
   "source": [
    "for row in simple_font_ds.take(10):\n",
    "  print(row[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_files = tf.data.Dataset.list_files(\"fonts/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "     b'fonts/GLOUCESTER.csv'\n",
      "     b'fonts/MODERN.csv'\n",
      "     b'fonts/CENTAUR.csv'\n",
      "     b'fonts/CITYBLUEPRINT.csv'\n",
      "     b'fonts/E13B.csv'\n",
      "    ...\n",
      "\n",
      "Epoch 2:\n",
      "     b'fonts/NUMERICS.csv'\n",
      "     b'fonts/BRITANNIC.csv'\n",
      "     b'fonts/BLACKADDER.csv'\n",
      "     b'fonts/EDWARDIAN.csv'\n",
      "     b'fonts/HANDPRINT.csv'\n",
      "    ...\n"
     ]
    }
   ],
   "source": [
    "print('Epoch 1:')\n",
    "for f in list(font_files)[:5]:\n",
    "  print(\"    \", f.numpy())\n",
    "print('    ...')\n",
    "print()\n",
    "\n",
    "print('Epoch 2:')\n",
    "for f in list(font_files)[:5]:\n",
    "  print(\"    \", f.numpy())\n",
    "print('    ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_font_csv_ds(path):\n",
    "  return tf.data.experimental.CsvDataset(\n",
    "    path, \n",
    "    record_defaults=font_column_types, \n",
    "    header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_rows = font_files.interleave(make_font_csv_ds,\n",
    "                                  cycle_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-90-06da9fcfb5e9>:5: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  fonts_dict['character'].append(chr(row[2].numpy()))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>font_name</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FELIX TITLING</td>\n",
       "      <td>ﬂ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAVIE</td>\n",
       "      <td>ﬂ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV_BOLI</td>\n",
       "      <td>ﷲ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FELIX TITLING</td>\n",
       "      <td>ﬁ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RAVIE</td>\n",
       "      <td>ﬁ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MV_BOLI</td>\n",
       "      <td>◌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FELIX TITLING</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RAVIE</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MV_BOLI</td>\n",
       "      <td>™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FELIX TITLING</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       font_name character\n",
       "0  FELIX TITLING         ﬂ\n",
       "1          RAVIE         ﬂ\n",
       "2        MV_BOLI         ﷲ\n",
       "3  FELIX TITLING         ﬁ\n",
       "4          RAVIE         ﬁ\n",
       "5        MV_BOLI         ◌\n",
       "6  FELIX TITLING         \n",
       "7          RAVIE         \n",
       "8        MV_BOLI         ™\n",
       "9  FELIX TITLING         "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fonts_dict = {'font_name':[], 'character':[]}\n",
    "\n",
    "for row in font_rows.take(10):\n",
    "  fonts_dict['font_name'].append(row[0].numpy().decode())\n",
    "  fonts_dict['character'].append(chr(row[2].numpy()))\n",
    "\n",
    "pd.DataFrame(fonts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=2048\n",
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=BATCH_SIZE, num_epochs=1,\n",
    "    num_parallel_reads=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=2048\n",
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = \"fonts/*.csv\",\n",
    "    batch_size=BATCH_SIZE, num_epochs=1,\n",
    "    num_parallel_reads=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\n",
      "CPU times: user 35 s, sys: 14.2 s, total: 49.2 s\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_ds.take(20)):\n",
    "  print('.',end='')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_files = tf.data.Dataset.list_files(\"fonts/*.csv\")\n",
    "fonts_lines = fonts_files.interleave(\n",
    "    lambda fname:tf.data.TextLineDataset(fname).skip(1), \n",
    "    cycle_length=100).batch(BATCH_SIZE)\n",
    "\n",
    "fonts_fast = fonts_lines.map(lambda x: tf.io.decode_csv(x, record_defaults=font_column_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\n",
      "CPU times: user 4.6 s, sys: 0 ns, total: 4.6 s\n",
      "Wall time: 4.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_fast.take(20)):\n",
    "  print('.',end='')\n",
    "\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
